---
title: "PSTAT 131 Final Project - Sloth Species"
author: 'Mirabelle Le'
output: html_document
date: '2022-05-31'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

The goal of this project is to generate a model that will predict a sloth's species, seeing if a sloth is two-toed or three-toed.

## All Things Sloths!

If you don't know what sloths are, they are an adorable species of animals well known for being slow and lethargic. These creatures spend a majority of their lives hanging on trees, sleeping, and remaining hidden from predators. The animals live solitary lives and travel from tree to tree using canopy vines. Located in places such as Brazil and Panama, this strange and wonderful animal needs healthy forests to survive. (Source: https://www.worldwildlife.org/stories/why-are-sloths-slow-and-six-other-sloth-facts)

There are two main species of sloth, identified by whether they have two or three claws on their front feet. The two species are quite similar in appearance, with roundish heads, sad-looking eyes, tiny ears, and stubby tails. Two-toed sloths are slightly bigger and tend to spend more time hanging upside-down than their three-toed cousins, who will often sit upright in the fork of a tree branch. Three-toed sloths have facial coloring that makes them look like they're always smiling. They also have two extra neck vertebrae that allow them to turn their heads almost all the way around! (Source: https://kids.nationalgeographic.com/animals/mammals/facts/sloth)

Here are a few cute pictures of sloths!

![A cute sloth!](/Users/mirabellele/Desktop/finalproject_131/sloth1.jpeg)

![A sloth hanging eating fruits!](/Users/mirabellele/Desktop/finalproject_131/sloth2.jpeg)

![A little sloth hanging on a branch!](/Users/mirabellele/Desktop/finalproject_131/sloth3.jpeg)

## Project Objectives

1. Clean the data and visualize the distribution of the features.
2. Create a classification model to predict if a sloth is two toed or three toed.


# Overview of Dataset

Let's begin by exploring the dataset and loading all of the data and necessary packages.

```{r, include=FALSE}
# Loading packages
library(tidymodels)
library(ISLR) 
library(ISLR2) 
library(ggplot2)
library(corrplot)
library(discrim)
library(poissonreg)
library(corrr)
library(klaR) # for naive bayes
tidymodels_prefer()
library(rpart.plot)
library(vip)
library(janitor)
library(randomForest)
library(xgboost)
library(ranger)
library(kknn)
library(kknn)
```


```{r}
# Loading the data
sloths <- read.csv("/Users/mirabellele/Desktop/finalproject_131/sloth_data.csv") 
head(sloths)
```

In this data set, our dataset contains 5000 observations and 7 predictors. The dataset includes information on the sizes of sloths, with each row being a different observed sloth. The variables include the claw length, the endangered category for the sloth, what species the sloth is, what subspecies the sloth is, its size, tail length, and weight. In addition, there is a column for the index of each sloth beginning at 0 and ending at 4999 (which I removed later on).

The link to the dataset can be found here: https://www.kaggle.com/datasets/bertiemackie/sloth-species . 

### Description of Each Attribute

* `x` : Index for each sloth
* `claw_length_cm` : The claw length of a sloth in centimeters
* `endangered` : The endangered category for the sub species
* `size_cm` : The size of the sloth (head & body) in cm
* `specie` : The species of sloth, two or three toed
* `sub_specie` : The sub specie of sloth (Pygmy three-toed sloth, Hoffman’s two-toed sloth, Linnaeus’s two-toed sloth, Pale-throated sloth, Brown-throated sloth, Maned three-toed sloth)
* `tail_length_cm` : The length of the sloths tail in cm
* `weight_kg` : The weight of the sloth in kg

# Data Cleaning

```{r}
# Cleaning and deselecting variables
sloths <- sloths %>% 
  clean_names() %>%
  select(-x) 
```

I ended up removing the `x` column that contains the index for each sloth since I thought it was misleading since it started at 0 and ended at 4999 I believed it was unnecessary to include in my data. 

```{r}
# Factoring variables
sloths$endangered <- factor(sloths$endangered)
sloths$specie <- factor(sloths$specie)
sloths$sub_specie <- factor(sloths$sub_specie)
```

I made `endangered`, `specie`, and `sub_specie` into factors to categorize the data and stored it as levels. I believe that it would be useful in data analysis for statistical modeling.

### Data Splitting

The data was split in a 80% training, 20% testing split. I also decided to use stratified sampling.

The data split was conducted prior to the EDA as I did not want to know anything about my testing data set before I tested my model on those observations.

```{r}
set.seed(2424)

sloths_split <- initial_split(sloths, prop = 0.80,
                                strata = specie) # split on specie
sloths_train <- training(sloths_split) # split sloths data into training & testing set
sloths_test <- testing(sloths_split)
```

The training data contains 3999 observations and the testing data contains 1001 observations.


# Exploratory Data Analysis (EDA)

### Let's explore the different variables and visualize the different distributions of the features.

```{r}
sloths %>% 
  ggplot(aes(x = claw_length_cm)) +
  geom_histogram(bins = 60) +
  theme_bw() +
  labs(
    title = "Claw Lengths of Sloths",
    x = "Claw Length (cm)",
    y = "Count"
  ) 
```

From the graph above, we can observe that the distribution of the sloth claw lengths closely follow a normal distribution.


```{r}
sloths %>% 
  ggplot(aes(x = tail_length_cm)) +
  geom_histogram(bins = 60) +
  theme_bw() +
  labs(
    title = "Tail Lengths of Sloths",
    x = "Tail Length (cm)",
    y = "Count"
  ) 
```

From the above graph, we can observe that the tail length of sloths in this dataset do not follow a normal distribution. It somewhat resembles a bimodel distribution. 

```{r}
sloths %>% 
  ggplot(aes(x = weight_kg)) +
  geom_histogram(bins = 60) +
  theme_bw() +
  labs(
    title = "Weight of Sloths",
    x = "Weight (kg)",
    y = "Count"
  ) 
```

From the graph above, we can observe that the distribution of the weights of the sloths closely follow a normal distribution.

```{r}
ggplot(sloths, aes(endangered)) +
  geom_bar() +
  labs(
    title = "Different Endangered Statuses of Sloths",
    x = "Endangered Status",
    y = "Count"
  ) +
  coord_flip()
```

Here, we can see the different endangered statuses of sloths. We can see that a large majority of the observed sloths fall under the least concern status, which is good! There are a good amount of sloths that also fall under the vulnerable category, and a small amount of sloths fall under the critically endangered category.

```{r}
ggplot(sloths, aes(x=size_cm, y=weight_kg)) + 
    geom_point() 
```

```{r}
ggplot(sloths, aes(x=size_cm, y=tail_length_cm)) + 
    geom_point() 
```

From the two above graphs, we find something very interesting! We can see that there are two clusters of data in both graphs when looking specifically at the different sizes of the sloths. I hypothesize that these two clusters represent the two different types of sloths (two-toed and three-toed).

Next, let's see how important the variable `specie` is to the rest of the data. This way, we'll be able to understand the value of the species of the sloth in relation to other variables.

```{r}
ggplot(sloths, aes(x=specie, y=size_cm, color = specie)) + 
  geom_boxplot()
```

The above graph helps us understand the distribution of the data in the dataset in regards to sloth species. Here, we can see that three toed sloths are smaller than two toed sloths. We can also see that the range of the sizes of three toed sloths are much larger in comparison to the range of the sizes of two toed sloths. This makes sense as upon doing some research, two-toed sloths are actually larger than three-toed sloths!

```{r}
ggplot(sloths, aes(x=specie, y=weight_kg, color = specie)) + 
  geom_boxplot()
```

From the above graph, we can also see the distributions of the weights of different species of sloths. We can see that in general, three toed sloths do weigh less than two toed sloths. In addition, we can also see a couple of outliers of the data in regards to both three toed and two toed sloths. This makes sense as upon doing some research, two-toed sloths are actually larger than three-toed sloths and would weigh more!

```{r}
ggplot(sloths, aes(specie)) +
  geom_bar() +
  labs(
    title = "Count of Different Sloth Species",
    x = "Species",
    y = "Count"
  ) +
  coord_flip()
```

```{r}
sum(sloths$specie == "two_toed") # number of two-toed sloths
sum(sloths$specie == "three_toed") # number of three-toed sloths

sum(sloths$specie == "two_toed") / nrow(sloths) # proportion of two-toed
sum(sloths$specie == "three_toed") / nrow(sloths) # proportion of three-toed
```

From the above graph, we can see the difference between the number of two-toed sloths and three-toed sloths. From our code, we gather that there are 2338 two-toed sloths and 2662 three-toed sloths within the data. We can then calculate the proportion of two-toed and three-toed sloths, 46.76% and 53.24%, respectively. 

```{r}
ggplot(sloths, aes(sub_specie)) +
  geom_bar() +
  labs(
    title = "Count of Different Sloth Sub-Species",
    x = "Sub-species",
    y = "Count"
  ) +
  coord_flip()
```

Here, I've made a histogram displaying the count of different sub-species of sloths within the dataset. We can see all of the different types of sloths that make up the dataset!

```{r}
sloths_small <- sloths %>% 
  select(size_cm, tail_length_cm, weight_kg)
M = cor(sloths_small)

corrplot(M, order = 'AOE', method = 'number')
```

Above is a correlation matrix to help show the positive and negative correlations that different variables within the dataset have with one another. We can see from the correlation matrix that `size_cm` and `weight_kg` have a positive relationship with one another. This makes sense because as the size of the sloth increases, its weight should also increase! On the other hand, we also see that `weight_kg` and `tail_length_cm` have a negative relationship with each other as well as `tail_length_cm` and `size_cm`. We can conclude that as a sloth increases in weight or size, its tail length will decrease. Upon doing some research, two-toed sloths are in fact bigger than three-toed sloths and have shorter tails, so the data makes sense!


# Model Building 

The whole model building process was quite long and took me a bit but this is how I approached it:

1. Building the model
2. Running the model
3. Analyzing the model

### Making My Recipe

```{r}
sloths_recipe <- 
  recipe(specie ~ ., data = sloths_train%>%select(-c(sub_specie, endangered))) %>% 
  step_dummy(all_nominal_predictors()) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())
```

Above, I made my recipe to help predict `specie` with all nominal predictors except `sub_specie` and `endangered` since they were categorical variables. 

### Looking at Logistic Regresssion, LDA, and QDA Models

```{r}
sloths_folds <- vfold_cv(sloths_train, v = 10, repeats=2)
```

Here, I folded my training data into 10 folds with 2 repeats.

```{r}
# logistic regression model
log_reg <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")
log_wkflow <- workflow() %>% 
  add_model(log_reg) %>% 
  add_recipe(sloths_recipe)

# lda model
lda_mod <- discrim_linear() %>% 
  set_mode("classification") %>% 
  set_engine("MASS")
lda_wkflow <- workflow() %>% 
  add_model(lda_mod) %>% 
  add_recipe(sloths_recipe)

# qda model 
qda_mod <- discrim_quad() %>% 
  set_mode("classification") %>% 
  set_engine("MASS")
qda_wkflow <- workflow() %>% 
  add_model(qda_mod) %>% 
  add_recipe(sloths_recipe)
```

Afterwards, I set up the model and workflows for the logistic regression model, linear discriminant analysis model, and quadratic discriminant analysis model.

```{r, eval=FALSE}
log_fit_rs <- log_wkflow %>% fit_resamples(sloths_folds)
lda_fit_rs <- lda_wkflow %>% fit_resamples(sloths_folds)
qda_fit_rs <- qda_wkflow %>% fit_resamples(sloths_folds)
```

```{r}
load("fitmodels.rda")
```

Next, I fit the models to the folded data. I also decided to run the code once, using an R script, and stored my results, using loading and saving, but set eval = FALSE in the code chunks. This was so I wouldn't have to run it every time I knitted the file. 

```{r}
collect_metrics(log_fit_rs)
collect_metrics(lda_fit_rs)
collect_metrics(qda_fit_rs)
```

Here, I used collect_metrics() to print the accuracy and ROC AUC of the performance metric accuracy across all folds for each of the models. From the above, we can see that the linear discriminant analysis model had the highest accuracy with an accuracy of 97.45%. 

```{r}
log_model_fit <- log_wkflow %>% fit(sloths_train)
```

Here, I fit the logistic regression model to the entire training dataset to analyze the performance of the training data.

```{r}
log_test_acc <- predict(log_model_fit, new_data = sloths_test)%>%
  bind_cols(sloths_test%>%dplyr::select(specie))%>%
  accuracy(truth = specie, estimate = .pred_class)
log_test_acc
```

Finally, with my fitted model, I used predict(), bind_cols(), and accuracy() to assess my model’s performance on the testing data. From the above, we can see that the testing data had an accuracy of 97.20%. For logistic regression, the model actually performed better in terms of accuracy on the testing set than it did on the training set. This can happen sometimes, and is likely because this is not a difficult prediction problem – and, in this case, possibly because the assumptions of logistic regression are met.


# Preparing & Running The Models for Repeated Cross Validation
I decided to run repeated cross fold validation on the following three models due to the large number of categorical variables in my data set.

* Random Forest
* Boosted Trees
* Nearest Neighbors

### Random Forest Model

First, I set up the model and workflow. Here, I tuned min_n and mtry, set mode to "classification" (because my outcome is a categorical variable), and used the ranger engine. I stored this model and my recipe in a workflow.

```{r}
rf_model <- 
  rand_forest(
              min_n = tune(),
              mtry = tune(),
              mode = "classification") %>% 
  set_engine("ranger")

rf_workflow <- workflow() %>% 
  add_model(rf_model) %>% 
  add_recipe(sloths_recipe)
```

Next, I set up the tuning grid, and I updated the parameters to range from 1 to 4 and set up a tuning grid with 2 levels.

```{r}
rf_params <- parameters(rf_model) %>% 
  update(mtry = mtry(range= c(1, 4)))

rf_grid <- grid_regular(rf_params, levels = 2)
```

Then, I executed my model by tuning and fitting. I wrote out the results and the workflow so I would not need to run it again:

```{r,eval=FALSE}
rf_tune <- rf_workflow %>% 
  tune_grid(
    resamples = sloths_folds, 
    grid = rf_grid)

# Write Out Results & Workflow ----
save(rf_tune, rf_workflow, file = "rf_tune.rda")
```


### Boosted Tree Model

In a similar process, I set the model with tuning parameters min_n, mtry, and learn_rate . I set the engine as xgboost. I created a workflow.

```{r}
bt_model <- boost_tree(mode = "classification",
                       min_n = tune(),
                       mtry = tune(),
                       learn_rate = tune()) %>% 
  set_engine("xgboost")

bt_workflow <- workflow() %>% 
  add_model(bt_model) %>% 
  add_recipe(sloths_recipe)
```

Then, I set up a tuning grid, and used the same parameters as above.

```{r}
bt_params <- parameters(bt_model) %>% 
  update(mtry = mtry(range= c(1, 4)),
         learn_rate = learn_rate(range = c(-5, 0.2))
  )

# define grid
bt_grid <- grid_regular(bt_params, levels = 2)
```

Then, I executed the model by tuning and fitting. I saved the results and the workflow so I would not need to run that code chunk again.

```{r,eval=FALSE}
bt_tune <- bt_workflow %>% 
  tune_grid(
    resamples = sloths_folds, 
    grid = bt_grid
    )

# Write Out Results & Workflow ----
save(bt_tune, bt_workflow, file = "bt_tune.rda")
```


### Nearest Neighbors Model 

Lastly, I ran repeated cross fold validation on the Nearest Neighbor model similarly to the previous two models. For nearest neighbor, I tuned only neighbors as the model’s other defaults are fine. I also set the workflow and added the recipe.

```{r}
knn_model <- 
  nearest_neighbor(
    neighbors = tune(),
    mode = "classification") %>% 
  set_engine("kknn")

knn_workflow <- workflow() %>% 
  add_model(knn_model) %>% 
  add_recipe(sloths_recipe)
```

Next, I set up a tuning grid and defined it.

```{r}
# set-up tuning grid ----
knn_params <- parameters(knn_model)


# define grid
knn_grid <- grid_regular(knn_params, levels = 2)
```

Then I tuned and fit the repeated cross fold validation. Like before, I wrote out the results and workflow so I could access them later without having to refit the model.


```{r,eval=FALSE}
knn_tune <- knn_workflow %>% 
  tune_grid(
    resamples = sloths_folds, 
            grid = knn_grid)

save(knn_tune, knn_workflow, file = "knn_tune.rda")
```


## Model Analysis

With each of the three cross validation model R scripts, complete and written out to a file, I loaded the results into my R environment.

```{r}
load("bt_tune.rda")
load("rf_tune.rda")
load("knn_tune.rda")
```

### Random Forest Model

```{r}
autoplot(rf_tune, metric = "roc_auc")
```

Looking at the `autoplot()` function, we can see that `roc_auc` decreases as the number of randomly selected predictors increases.

```{r}
show_best(rf_tune, metric = "roc_auc") %>% select(-.estimator, -.config)
```

Using the show_best() function, the biggest mean is 0.9962436	, with mtry = 1 and min_n = 2. This is pretty good, because it means that the model's predictions were 99.62% correct!

### Boosted Tree Model

```{r}
autoplot(bt_tune, metric = "roc_auc")
```

```{r}
show_best(bt_tune, metric = "roc_auc") %>% select(-.estimator, -.config)
```

Using the show_best() function, the highest mean is 0.9945630, with learn_rate = 1.58, mtry = 4, and min_n = 40. This means that the model's predictions were about 99.46% correct!

### Nearest Neighbors Model

```{r}
autoplot(knn_tune, metric = "roc_auc")
```



```{r}
show_best(knn_tune, metric = "roc_auc") %>% select(-.estimator, -.config)
```

Using the show_best() function, the highest mean is 0.9945245, with neighbors = 15. This does not beat our random forest model.

We will now continue with the Random Forest Model being the model that performed the best. 


## Final Model Building

We’ll create a workflow that has tuned in the name, so we can identify it. We’ll finalize the workflow by taking the parameters from the best model (the random forest model) using the `select_best()` function.

```{r}
rf_workflow_tuned <- rf_workflow %>% 
  finalize_workflow(select_best(rf_tune, metric = "roc_auc"))
```

Next, we run the fit!

```{r}
rf_results <- fit(rf_workflow_tuned, sloths_train)
```


## Analysis of the Testing Set

```{r}
rf_test_acc <- predict(rf_results, new_data = sloths_test)%>%
  bind_cols(sloths_test%>%dplyr::select(specie))%>%
  accuracy(truth = specie, estimate = .pred_class)

rf_test_acc
```

Our model returned an accuracy of 0.97003 on our testing data, which means that 97.003% of our testing data is accurate. 

```{r}
rf_train_acc <- predict(rf_results, new_data = sloths_train)%>%
  bind_cols(sloths_train%>%dplyr::select(specie))%>%
  accuracy(truth = specie, estimate = .pred_class)

rf_train_acc
```

From evaluating the accuracy of our training data, we receive that it is 100% accurate. Unfortunately, by looking at the accuracy of the training and testing data on the random forest model, we see that our model did not do such a great job as it overfitted to the training data.This means that the noise or random fluctuations in the training data were picked up and learned as concepts by the model. The problem is that these concepts do not apply to new data and negatively impact the models ability to generalize.


# Conclusion 

This section summarizes our project and highlights several key findings. Our goal waas to use machine learning models on a dataset of sloths to predict a species of sloth.

We achieved this in two parts (objectives):

1. Clean the data and visualize the distribution of the features.
2. Create a classification model to predict if a sloth is two toed or three toed.


## Models

We ended up making 6 classification models: Logistic Regression, LDA, QDA, Random Forest, Boosted Tree, and Nearest Neighbors.

We used a 80% train and 20% test set split for our classification models.


## Our Best Fitting Model

Our best fitting model at predicting sloth species ended up being the Random Forest model. The Random Forest model provides higher accuracy through cross validation. Although our model ended up overfitting to the training data, we can learn from this! Decision trees are a nonparametric machine learning algorithm that is very flexible and is subject to overfitting training data. This problem can be addressed by pruning a tree after it has learned in order to remove some of the detail it has picked up.

## Overall Key Findings

* The distribution of the sloth claw lengths and sloth weight closely follow a normal distribution.
* The tail length of sloths in this dataset do not follow a normal distribution and actually resembles a bimodel distribution. 
* Two-toed sloths are larger in size and heavier in weight in comparison to three-toed sloths.
* The variables `size_cm` and `weight_kg` have a positive relationship with one another. On the other hand, we also saw that `weight_kg` and `tail_length_cm` have a negative relationship with each other as well as `tail_length_cm` and `size_cm`. 
